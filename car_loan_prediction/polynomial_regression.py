# -*- coding: utf-8 -*-
"""polynomial_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1danUhNAirUIQrIR07klycq4wysDnAZHB

# **Polynomial Regression**

## Importing the libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler

"""## Importing the dataset"""

dataset = pd.read_csv('Loan_Dataset.csv')
X = dataset.iloc[:, 1:-2].values 
y = dataset.iloc[:, -2].values

dataset

print(X)

print(X[0])

print(y)

print(y[0])

"""## Encoding categorical data"""

# ['M' 59 'No' 1 'Graduate' 'Priv Sector' 2314491 219621 571 'Average' 1]

ct = ColumnTransformer(
    [
        ("scaling", StandardScaler(), [1, 3, 6, 7, 8, 10]),
        ("onehot", OneHotEncoder(sparse=False), [0, 2, 4, 5, 9]),
    ]
)

X = np.array(ct.fit_transform(X))

print(X)

print(X[0])

"""## Splitting the dataset into the Training set and Test set"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""## Training the Polynomial Regression model on the Training set"""

# Fit a polynomial regression model to the training data
poly_features = PolynomialFeatures(degree=2)
X_train_poly = poly_features.fit_transform(X_train)
poly_model = LinearRegression()
poly_model.fit(X_train_poly, y_train)

"""## Predicting the Test set results"""

X_test_poly = poly_features.transform(X_test)
y_pred = poly_model.predict(X_test_poly)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

"""## Evaluating the performance of the model


To calculate the accuracy of a polynomial regression model, you can use the R-squared (coefficient of determination) metric. R-squared is a statistical measure that represents the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, with higher values indicating a better fit of the model to the data.
"""

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("RMSE:", rmse)
print("RÂ² score:", r2)

"""## Plot the predicted vs actual values"""

plt.scatter(y_test, y_pred, c ="pink",
            linewidths = 2,
            marker ="s",
            edgecolor ="green",
            s = 50)
plt.xlabel('Actual values')
plt.ylabel('Predicted values')
plt.title('Actual vs Predicted values')
plt.show()

"""## Demo"""

new_user_data = np.array([
    ['M', 32, 'No', 1, 'Not Graduate', 'Agriculturist', 1159941, 0, 853, 'Excellent', 1]
])

new_user_data = ct.transform(new_user_data)
new_user_data_poly = poly_features.transform(new_user_data)
new_user_loan_amount = poly_model.predict(new_user_data_poly)

# Printing the predicted loan amount
print("Predicted loan amount for the new user:", new_user_loan_amount[0])

